{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting the random seed so there is consistent data splitting between runs\n",
    "tf.random.set_seed(42)\n",
    "# importing the lowPPM matrix\n",
    "allData = r\"../Output/LowPPMMatrix.csv\"\n",
    "\n",
    "# Reading in the data to csv and removing any data at 150 ppm as this was incorrect data from testing\n",
    "# NOTE: the 150 ppm is not in all outputs. but it is left in as a safeguard\n",
    "df = pd.read_csv(allData)\n",
    "df=df[df['Target PPM']!=150]\n",
    "# Dropping all unneeded columns from the output\n",
    "df = df.drop(columns=['Unnamed: 0','lowInterval','highInterval','Ratio'])\n",
    "print(df.head())\n",
    "\n",
    "# Declaring what sensor is used for the test set\n",
    "test_sensor_id = 0  # Replace with the ID of the sensor you want in the test set\n",
    "train_data = df[df['SensorID'] != test_sensor_id]\n",
    "test_data = df[df['SensorID'] == test_sensor_id]\n",
    "\n",
    "# Drop the SensorID column as we don't need it anymore\n",
    "train_data = train_data.drop(columns=['SensorID'])\n",
    "test_data = test_data.drop(columns=['SensorID'])\n",
    "# Convert to TensorFlow tensors\n",
    "train_data_tf = tf.convert_to_tensor(train_data, dtype=tf.float32)\n",
    "test_data_tf = tf.convert_to_tensor(test_data, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Randomizes the data for training to minimize fitting to false trends\n",
    "train_data_shuffled = tf.random.shuffle(train_data_tf, seed=42)\n",
    "\n",
    "# Separate features and labels\n",
    "x_train, y_train = train_data_shuffled[:, 1:], train_data_shuffled[:, 0]\n",
    "x_test, y_test = test_data_tf[:, 1:], test_data_tf[:, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mean squared error function\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "# Root mean squared error function\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(mse_loss(y_pred - y_true))\n",
    "\n",
    "# R-Squared function to test fit of model\n",
    "def r_squared(y_true, y_pred):\n",
    "    residual = tf.reduce_sum(tf.square(tf.subtract(y_true, y_pred)))\n",
    "    total = tf.reduce_sum(tf.square(tf.subtract(y_true, tf.reduce_mean(y_true))))\n",
    "    r2 = tf.subtract(1.0, tf.divide(residual, total))\n",
    "    return r2\n",
    "\n",
    "# Used to trace history of RMSE as the neural network gets trained\n",
    "class RMSEHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        self.modelRMSE = []\n",
    "        self.validationRMSE = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        self.modelRMSE.append(logs.get('rmse'))\n",
    "        self.validationRMSE.append(logs.get('val_rmse'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rmse_history = RMSEHistory()\n",
    "# Compile and train the model\n",
    "input_shape = (x_train.shape[1],)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize a CSV file to store the results\n",
    "csvfile = open('experiment_results.csv', 'w', newline='')\n",
    "csvwriter = csv.writer(csvfile)\n",
    "csvwriter.writerow(['BaseNum', 'Run', 'Test_RMSE', 'Test_Accuracy'])\n",
    "\n",
    "for baseNum in tqdm(range(1, 33), desc='BaseNum Loop'):  # Wrap outer loop with tqdm\n",
    "    for run in tqdm(range(1, 101), desc=f'Run Loop for BaseNum {baseNum}', leave=False):  # Wrap inner loop with tqdm\n",
    "\n",
    "\n",
    "        def build_model(input_shape, regularization_factor=0.01):\n",
    "            model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(baseNum * 2, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor), input_shape=input_shape),\n",
    "                tf.keras.layers.Dense(baseNum*4, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor)),\n",
    "                tf.keras.layers.Dense(baseNum*4, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor)),\n",
    "                tf.keras.layers.Dense(baseNum*2, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor)),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "            return model\n",
    "\n",
    "        with tf.device('/GPU:0'):\n",
    "            model = build_model(input_shape)\n",
    "            model.compile(optimizer='adam', loss=mse_loss, metrics=[r_squared, rmse])\n",
    "            model.fit(x_train, y_train, epochs=1000, batch_size=50, validation_split=0.2, callbacks=[rmse_history],verbose=0)\n",
    "            test_metrics = model.evaluate(x_test, y_test,verbose=0)\n",
    "            test_loss, test_accuracy, test_rmse = test_metrics[0], test_metrics[1], test_metrics[2]\n",
    "        # Save the results\n",
    "        csvwriter.writerow([baseNum, run, test_rmse, test_accuracy])\n",
    "        csvfile.flush()\n",
    "csvfile.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NOTE: with =2 (Or any small int) it is hit or miss whether the model will go down the best optimized path. rerun a few times to determine what the best value is\n",
    "#Used to quickly change size of neural net\n",
    "baseNum = 2\n",
    "\n",
    "# Define your original model with regularization\n",
    "def build_model(input_shape, regularization_factor=0.01):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(baseNum*2, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor), input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(baseNum*4, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor)),\n",
    "        tf.keras.layers.Dense(baseNum*4, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor)),\n",
    "        tf.keras.layers.Dense(baseNum*2, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor)),\n",
    "        # tf.keras.layers.Dense(baseNum, activation='relu', kernel_regularizer=regularizers.l2(regularization_factor)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    #regular model training\n",
    "    model = build_model(input_shape)\n",
    "    model.compile(optimizer='adam', loss=mse_loss, metrics=[r_squared, rmse])\n",
    "    model.fit(x_train, y_train, epochs=1000, batch_size=50, validation_split=0.2, callbacks=[rmse_history])\n",
    "    # if no improvement has been made in 100 generations (epochs) stop the model\n",
    "    if early_stopping.stopped_epoch > 0:\n",
    "        print(f\"Early stopping occurred at epoch {early_stopping.stopped_epoch}\")\n",
    "        print(f\"Restoring model weights from the end of the best epoch.\")\n",
    "    else:\n",
    "        print(\"Early stopping did not occur.\")\n",
    "\n",
    "    test_metrics = model.evaluate(x_test, y_test)\n",
    "    test_loss, test_accuracy, test_rmse = test_metrics[0], test_metrics[1], test_metrics[2]\n",
    "    print(f\"Test Loss (MSE): {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy*100}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "    # Plotting RMSE values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(rmse_history.modelRMSE, label='Train RMSE')\n",
    "    plt.plot(rmse_history.validationRMSE, label='Validation RMSE')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('RMSE During Training')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Pruning model. use the final_sparsity to trim the model. 0.5 means 50% of the nodes get trimmed, 0.9 means 90% of the nodes get trimmed. typically 0.6 is a good starting point for this\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.0,\n",
    "                                                    final_sparsity=0.0,\n",
    "                                                    begin_step=len(x_train) // 50 * 10,\n",
    "                                                    end_step=len(x_train) // 50 * 500)\n",
    "    }\n",
    "\n",
    "    model_for_pruning = sparsity.prune_low_magnitude(model, **pruning_params)\n",
    "    model_for_pruning.compile(optimizer='adam', loss=mse_loss, metrics=[r_squared,rmse])\n",
    "\n",
    "    callbacks = [\n",
    "        sparsity.UpdatePruningStep(),\n",
    "        early_stopping,\n",
    "        rmse_history\n",
    "    ]\n",
    "\n",
    "    model_for_pruning.fit(x_train, y_train, epochs=200, batch_size=50, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "    # Remove the pruning wrappers to finalize the model\n",
    "    final_model = sparsity.strip_pruning(model_for_pruning)\n",
    "\n",
    "\n",
    "if early_stopping.stopped_epoch > 0:\n",
    "    print(f\"Early stopping occurred at epoch {early_stopping.stopped_epoch}\")\n",
    "    print(f\"Restoring model weights from the end of the best epoch.\")\n",
    "else:\n",
    "    print(\"Early stopping did not occur.\")\n",
    "\n",
    "# Make predictions\n",
    "with tf.device('/GPU:0'):  # This line is optional\n",
    "    test_metrics = model.evaluate(x_test, y_test)\n",
    "    test_loss, test_accuracy, test_rmse = test_metrics[0], test_metrics[1], test_metrics[2]\n",
    "    print(f\"Test Loss (MSE): {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy*100}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "\n",
    "\n",
    "# Plotting RMSE values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rmse_history.modelRMSE, label='Train RMSE')\n",
    "plt.plot(rmse_history.validationRMSE, label='Validation RMSE')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE During Pruning')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# model.save('MethaneModel.keras')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Used to save the model\n",
    "model.save('MethaneModelBest391-2nodes.keras')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate predictions on the test data\n",
    "with tf.device('/GPU:0'):  # Optional\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "# Flatten y_test and y_pred for plotting\n",
    "y_test_flat = y_test.numpy().flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test_flat, y_pred_flat, alpha=0.5)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "\n",
    "# Plot a 45-degree line for reference\n",
    "plt.plot([-100, 1200], [-100, 1200], '--', color='gray')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "humidity_values = [0, 15, 30, 45, 60]  # Updated humidity values\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a 2x3 grid of subplots\n",
    "\n",
    "# Flatten the axs array in case it's 2D\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, H in enumerate(humidity_values):\n",
    "    # Filter the data for the given humidity value\n",
    "    mask = (df['RelativeHumidity'] >= H - 5) & (df['RelativeHumidity'] <= H + 5)\n",
    "    df_filtered = df.loc[mask]\n",
    "\n",
    "    xDataResistance1 = df_filtered.loc[:, 'Resistance']\n",
    "    xDataTemp1 = df_filtered.loc[:, 'Temperature']\n",
    "    xDataRH1 = df_filtered.loc[:, 'RelativeHumidity']\n",
    "    yDataTargetPPM1 = df_filtered.loc[:, 'Target PPM']\n",
    "\n",
    "    combined_df = pd.concat([xDataResistance1, xDataTemp1, xDataRH1], axis=1)\n",
    "\n",
    "\n",
    "    with tf.device('/GPU:0'):  # Optional\n",
    "          y_pred = model.predict(combined_df)  # Replace with your model's predict method\n",
    "    df_filtered['Predicted PPM'] = y_pred\n",
    "\n",
    "    # Create a scatter plot\n",
    "    sc = axs[i].scatter(yDataTargetPPM1, y_pred, alpha=0.5)\n",
    "\n",
    "    # Calculate mean prediction for each target PPM and plot it\n",
    "    mean_pred_per_target_ppm = df_filtered.groupby('Target PPM')['Predicted PPM'].mean()\n",
    "    axs[i].plot(mean_pred_per_target_ppm.index, mean_pred_per_target_ppm.values, color='r')\n",
    "\n",
    "    # Add a linear dotted line for reference\n",
    "    axs[i].plot(yDataTargetPPM1, yDataTargetPPM1, 'k:')\n",
    "\n",
    "    axs[i].set_xlabel('Target PPM')\n",
    "    axs[i].set_ylabel('Predicted PPM')\n",
    "    axs[i].set_title(f'Humidity={H}%')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
