{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relevant libraries\n",
    "import pandas as pd\n",
    "import scipy.optimize as sc\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import f\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from CSV file\n",
    "file2 = pd.read_csv(\"../Output/allDataEver.csv\")\n",
    "# Extract the columns from the data\n",
    "#file2=file2[file2['Target PPM']<=500]\n",
    "\n",
    "file2=file2[file2['Target PPM']!=150]\n",
    "# Separate the independent and dependent variables\n",
    "X = file2.drop('Target PPM', axis='columns')\n",
    "y = file2.loc[:, 'Target PPM']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Funk Equation\n",
    "# a*R+b\n",
    "# a*np.exp(-1*R*b+c)+d\n",
    "# a*R**b+c\n",
    "# a*R**b+c*H*(a*R**b+c)+d  (Basically Bastviken)\n",
    "# (a*np.exp(-1*R*b+c)+d)+f*H*(a*np.exp(-1*R*b+c)+d)+g\n",
    "# a*np.exp(-1*R*b+c)+d*np.exp(-1*H*f+g)+h (Funk Equation)\n",
    "# a*np.exp((-1*R*b+c)+(-1*H*d+e))+f 4.2\n",
    "#                                                           W/1000  W/500   UV500   UV1000\n",
    "# a**((-1*R*b+c)+(-1*H*d+e))+f 6.4                          87.79   42.64   62.74   116.35\n",
    "# a**((-1*R*b)+(-1*H*c)+d)+e   6.5                          87.79\n",
    "\n",
    "# a**((((-1*R)/(H**b))*c)+(-1*H*d)+e)+f 7.1                 74.09   35.76   62.37   113.46\n",
    "\n",
    "\n",
    "# a**((((-1*R)/(H**b))*c)+(-1*H*d)+(-1*T*e)+f)+g 8.1\n",
    "# a**((((-1*R)/(H**b))*c)+(-1*H*d)+(-1*T*e)+(((-1)/(T*f*H**g))*h)+i)+j 8.2\n",
    "# a**((((-1*R)/(H**b))*c)+(-1*H*d)+(-1*T*e)+(((-1*T*f)/(H**g))*h)+i)+j 8.3                           5.764\n",
    "\n",
    "#a**((((-1*R)/(H**b))*c)+(-1*H*d)+(-1*T*e)+(((-1*T*f)/(H**g))*h)+i)+j*np.exp(-1*T*k)+l 9.1\n",
    "\n",
    "\n",
    "#0.97**((((-1*R)/(H**(-0.66)))*c)+(-1*H)+(1.21*T)+(((-1.22*T)/(H**0.23))*1.25)+-178.26)+j            5.865\n",
    "\n",
    "\n",
    "\n",
    "def funkEQ(X, a, b,c,d,e,f,g,h,i,j,k,l):\n",
    "    R, H, T = X\n",
    "    with np.errstate(over='ignore'):\n",
    "        stuff=a**((((-1*R)/(H**b))*c)+(-1*H*d)+(-1*T*e)+(((-1*T*f)/(H**g))*h)+i)+j*np.exp(-1*T*k)+l\n",
    "    return stuff\n",
    "p0 = 1, 1,1,1,1,1,1,1,1,1,1,1\n",
    "\n",
    "def residual(params, X, y):\n",
    "    return np.sum((y - funkEQ(X, *params))**2)\n",
    "\n",
    "# Perform curve fitting using the funct function, xDataResistance, and yDataTargetPPM data\n",
    "# Set the maximum number of function evaluations to 1000000\n",
    "for s in [0, 3, 5, 7, 8, 10, 13, 15]:\n",
    "    file2=file2[file2['SensorID']==s]\n",
    "    xDataResistance = file2.loc[:, 'Resistance']\n",
    "    xDataRatio = file2.loc[:, 'Ratio']\n",
    "    xDataRH = file2.loc[:, 'RelativeHumidity']\n",
    "    xDataTemp = file2.loc[:, 'Temperature']\n",
    "    yDataTargetPPM = file2.loc[:, 'Target PPM']\n",
    "    popt, pcov = sc.curve_fit(funkEQ, (xDataResistance, xDataRH, xDataTemp), yDataTargetPPM, p0, maxfev=1000000)\n",
    "\n",
    "# Print the optimized parameters as [a b c d e f]\n",
    "    print(popt)\n",
    "\n",
    "#########\n",
    "# Getting RMSE of Equation\n",
    "#########\n",
    "\n",
    "R_test = X_test.loc[:, 'Resistance']\n",
    "H_test = X_test.loc[:, 'RelativeHumidity']\n",
    "T_test = X_test.loc[:, 'Temperature']\n",
    "\n",
    "# Generate the predictions using the optimized parameters and the input data\n",
    "y_pred = funkEQ((R_test, H_test, T_test), *popt)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "testVal = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(testVal)\n",
    "\n",
    "#########\n",
    "# All the code needed to display predicted vs actual graphs\n",
    "#########\n",
    "\n",
    "# Degrees of freedom\n",
    "df = len(yDataTargetPPM) - len(popt)\n",
    "\n",
    "# Student's t value for the 95% confidence level\n",
    "t_val = t.ppf(1-0.05/2, df)\n",
    "\n",
    "# Compute the standard error of the parameters\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# Compute the standard error of the predictions\n",
    "def predict_std(X, popt, perr):\n",
    "    jac = np.array([funkEQ(X, *popt[:i], 1 if j == i else 0, *popt[i+1:]) for i,j in enumerate(range(len(popt)))]).T\n",
    "    return np.sqrt(np.sum((jac * perr) ** 2, axis=1))\n",
    "\n",
    "# Compute the 95% confidence intervals for the predicted values\n",
    "predict_std_val = predict_std((R_test, H_test, T_test), popt, perr)\n",
    "conf_int_lower = y_pred - t_val * predict_std_val\n",
    "conf_int_upper = y_pred + t_val * predict_std_val\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
