{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Relevant libraries\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import OptimizeWarning\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import warnings\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T20:36:37.779471Z",
     "start_time": "2023-08-14T20:36:37.309453Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-14T20:39:15.852407Z",
     "start_time": "2023-08-14T20:36:39.307753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:30<00:00, 662.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial conditions to get this optimization were: [  0  -1 -20  -9  18 -19]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 95\u001B[0m\n\u001B[1;32m     92\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m funkEQ((R_test, H_test), \u001B[38;5;241m*\u001B[39mpopt)\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# Calculate the mean squared error\u001B[39;00m\n\u001B[0;32m---> 95\u001B[0m testVal \u001B[38;5;241m=\u001B[39m \u001B[43mmean_squared_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28mprint\u001B[39m(testVal)\n\u001B[1;32m     98\u001B[0m \u001B[38;5;66;03m# Iterate through target PPM values and calculate the 95% confidence interval for each value\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:442\u001B[0m, in \u001B[0;36mmean_squared_error\u001B[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001B[0m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean_squared_error\u001B[39m(\n\u001B[1;32m    383\u001B[0m     y_true, y_pred, \u001B[38;5;241m*\u001B[39m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, multioutput\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform_average\u001B[39m\u001B[38;5;124m\"\u001B[39m, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    384\u001B[0m ):\n\u001B[1;32m    385\u001B[0m     \u001B[38;5;124;03m\"\"\"Mean squared error regression loss.\u001B[39;00m\n\u001B[1;32m    386\u001B[0m \n\u001B[1;32m    387\u001B[0m \u001B[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;124;03m    0.825...\u001B[39;00m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 442\u001B[0m     y_type, y_true, y_pred, multioutput \u001B[38;5;241m=\u001B[39m \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[1;32m    446\u001B[0m     output_errors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage((y_true \u001B[38;5;241m-\u001B[39m y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, weights\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:102\u001B[0m, in \u001B[0;36m_check_reg_targets\u001B[0;34m(y_true, y_pred, multioutput, dtype)\u001B[0m\n\u001B[1;32m    100\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[1;32m    101\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m--> 102\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_true\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    105\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m y_true\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    915\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    916\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    917\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    918\u001B[0m         )\n\u001B[1;32m    920\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 921\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    929\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m     )\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[0;31mValueError\u001B[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "# Load data from CSV file\n",
    "file2 = pd.read_csv(\"../Output/LowPPMMatrix.csv\")\n",
    "# Extract the columns from the data\n",
    "#file2=file2[file2['Target PPM']<=500]\n",
    "\n",
    "#file2=file2[file2['Target PPM']!=150]\n",
    "#file2=file2[file2['Target PPM']!=50]\n",
    "xDataResistance = file2.loc[:, 'Resistance']\n",
    "xDataRatio = file2.loc[:, 'Ratio']\n",
    "xDataRH = file2.loc[:, 'RelativeHumidity']\n",
    "xDataTemp = file2.loc[:, 'Temperature']\n",
    "yDataTargetPPM = file2.loc[:, 'Target PPM']\n",
    "\n",
    "#calculate abso.lute humidity in g/m^3\n",
    "P_actual_hPa = .8 * 1013.25\n",
    "e_sat_standard = 6.112 * np.exp((17.67 * xDataTemp) / (xDataTemp + 243.5))\n",
    "e_sat_actual = e_sat_standard * (P_actual_hPa / 1013.25)\n",
    "xDataAH = 1000*((xDataRH/100)*e_sat_actual)/(461.5*(xDataTemp+ 273.15))\n",
    "\n",
    "# Separate the independent and dependent variables\n",
    "X = file2.drop('Target PPM', axis='columns')\n",
    "y = file2.loc[:, 'Target PPM']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ignore all warnings in the code\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def funkEQ(X, a, b,c,d,e,f):\n",
    "    R, H = X\n",
    "    with np.errstate(over='ignore'):\n",
    "        stuff=a*np.exp((((-1*R)/(H**b))*c)+(-1*H*d)+e)+f\n",
    "    return stuff\n",
    "\n",
    "def optimize_parameters(p0):\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "            warnings.filterwarnings('ignore', category=OptimizeWarning)\n",
    "\n",
    "            popt, pcov = curve_fit(funkEQ, (xDataResistance, xDataRH), yDataTargetPPM, p0=p0, maxfev=1000000)\n",
    "\n",
    "        return (p0, popt, np.sum((yDataTargetPPM - funkEQ((xDataResistance, xDataRH), *popt))**2))\n",
    "    except Exception as e:\n",
    "        print(f\"Error with parameters {p0}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed()\n",
    "\n",
    "# Number of points to generate\n",
    "num_points = 100000\n",
    "\n",
    "initial_params = np.random.randint(-2, 2, size=(num_points, 6))\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "results = Parallel(n_jobs=num_cores)(delayed(optimize_parameters)(p) for p in tqdm(initial_params))\n",
    "\n",
    "# Filter out None, NaN, and Infinity results\n",
    "successful_results = [result for result in results\n",
    "                      if result is not None\n",
    "                      and not np.any(np.isnan(result[1]))\n",
    "                      and not np.any(np.isinf(result[1]))]\n",
    "\n",
    "init_params, fitted_params, residuals = zip(*successful_results)\n",
    "\n",
    "# Rank the parameters by their residual and only keep the top 10\n",
    "best_params = np.array(fitted_params)[np.argsort(residuals)[:10]]\n",
    "best_init = np.array(init_params)[np.argsort(residuals)[:10]]\n",
    "\n",
    "# The best parameters are the first in the sorted list\n",
    "#print('Fitted function parameters: a=%.3f, b=%.3f, c=%.3f d=%.3f, f=%.3f, g=%.3f' % (best_params[0][0], best_params[0][1], best_params[0][2], best_params[0][3], best_params[0][4], best_params[0][5]))\n",
    "\n",
    "print('The initial conditions to get this optimization were: '+str(best_init[0]))\n",
    "\n",
    "# Calculate RMSE for the best parameters\n",
    "popt=best_params[0]\n",
    "#best_params[0]=[18,  1,  4, 12,  0,  4, -7]\n",
    "# file2=file2[file2[\"SensorID\"]==3]\n",
    "# X = file2.drop('Target PPM', axis='columns')\n",
    "# y = file2.loc[:, 'Target PPM']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Extract the Resistance column from the X_test dataframe\n",
    "R_test = X_test.loc[:, 'Resistance']\n",
    "H_test = X_test.loc[:, 'RelativeHumidity']\n",
    "T_test = X_test.loc[:, 'Temperature']\n",
    "#popt = [38.538220,0.843161,4.637493,380.116483,0.06614,0.298036,-78.340227]\n",
    "#popt = best_params[0]\n",
    "# Generate the predictions using the optimized parameters and the input data\n",
    "y_pred = funkEQ((R_test, H_test), *popt)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "testVal = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(testVal)\n",
    "\n",
    "# Iterate through target PPM values and calculate the 95% confidence interval for each value\n",
    "for i in range(0, 1001, 200):\n",
    "\n",
    "    # Filter the data for the current target PPM value\n",
    "    df = file2[file2['Target PPM'] == i]\n",
    "\n",
    "    # Calculate the model output using the filtered data and optimized parameters\n",
    "    myData = funkEQ((df.loc[:, 'Resistance'], df.loc[:, 'RelativeHumidity']), *popt)\n",
    "\n",
    "    # Calculate the 95% confidence interval using the t-distribution\n",
    "    low95, high95 = st.t.interval(0.95, len(myData)-1, loc=np.mean(myData), scale=st.sem(myData))\n",
    "\n",
    "\n",
    "    # Print the 95% confidence interval for the current target PPM value\n",
    "    print(\"The 95% Confidence Interval for \" + str(i) + \" is (\" + str(low95) + \", \" + str(high95) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
